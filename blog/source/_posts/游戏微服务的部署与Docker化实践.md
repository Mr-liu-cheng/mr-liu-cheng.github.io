---
title: æ¸¸æˆå¾®æœåŠ¡çš„éƒ¨ç½²ä¸DockeråŒ–å®è·µ
date: 2026-01-30 10:28:46
updated: 2026-01-30 10:28:46
tags: [å¾®æœåŠ¡,Docker]
categories: [ç½‘ç»œç¼–ç¨‹,å¾®æœåŠ¡,Docker]
keywords: åˆ†å¸ƒå¼
description:
---

# æ¸¸æˆå¾®æœåŠ¡çš„éƒ¨ç½²ä¸DockeråŒ–å®è·µ

æˆ‘å°†è¯¦ç»†è®²è§£å¦‚ä½•å°†æ¸¸æˆå¾®æœåŠ¡è¿›è¡ŒDockeråŒ–ï¼Œå¹¶ä½¿ç”¨ç¼–æ’å·¥å…·è¿›è¡Œéƒ¨ç½²ç®¡ç†ã€‚

## ä¸€ã€DockeråŒ–åŸºç¡€

### 1. ä¸ºä»€ä¹ˆéœ€è¦DockeråŒ–ï¼Ÿ

å¯¹äºæ¸¸æˆå¾®æœåŠ¡æ¶æ„ï¼ŒDockeræä¾›äº†ï¼š

- **ç¯å¢ƒä¸€è‡´æ€§**ï¼šå¼€å‘ã€æµ‹è¯•ã€ç”Ÿäº§ç¯å¢ƒå®Œå…¨ä¸€è‡´
- **å¿«é€Ÿéƒ¨ç½²**ï¼šç§’çº§å¯åŠ¨ï¼Œåˆ†é’Ÿçº§å…¨é›†ç¾¤éƒ¨ç½²
- **èµ„æºéš”ç¦»**ï¼šCPUã€å†…å­˜ã€ç½‘ç»œã€ç£ç›˜éš”ç¦»
- **å¼¹æ€§ä¼¸ç¼©**ï¼šæ ¹æ®è´Ÿè½½å¿«é€Ÿæ‰©ç¼©å®¹
- **ç‰ˆæœ¬ç®¡ç†**ï¼šé•œåƒç‰ˆæœ¬æ§åˆ¶ï¼Œè½»æ¾å›æ»š

### 2. æ¸¸æˆæœåŠ¡DockeråŒ–çš„æŒ‘æˆ˜

```
æŒ‘æˆ˜ï¼š
1. ç½‘ç»œå»¶è¿Ÿæ•æ„Ÿï¼ˆç‰¹åˆ«æ˜¯æˆ˜æ–—æœåŠ¡ï¼‰
2. é•¿è¿æ¥ç®¡ç†ï¼ˆç½‘å…³æœåŠ¡ï¼‰
3. çŠ¶æ€æœåŠ¡ï¼ˆéœ€è¦æŒä¹…åŒ–æ•°æ®ï¼‰
4. é«˜æ€§èƒ½è¦æ±‚ï¼ˆéœ€è¦æ¥è¿‘è£¸æœºæ€§èƒ½ï¼‰
```

## äºŒã€Dockerfileæœ€ä½³å®è·µ

### 1. å¤šé˜¶æ®µæ„å»ºç¤ºä¾‹

```dockerfile
# Dockerfile.activity
# ç¬¬ä¸€é˜¶æ®µï¼šæ„å»ºé˜¶æ®µ
FROM golang:1.21-alpine AS builder

# è®¾ç½®ç¼–è¯‘ç¯å¢ƒ
WORKDIR /app
COPY go.mod go.sum ./
RUN go mod download

# å¤åˆ¶æºç å¹¶ç¼–è¯‘
COPY . .
RUN CGO_ENABLED=0 GOOS=linux go build \
    -ldflags="-w -s" \
    -o activity-service \
    ./cmd/server

# ç¬¬äºŒé˜¶æ®µï¼šè¿è¡Œé˜¶æ®µ
FROM alpine:3.18

# å®‰è£…å¿…è¦çš„è¿è¡Œæ—¶ä¾èµ–
RUN apk --no-cache add \
    ca-certificates \
    tzdata \
    curl \
    && update-ca-certificates

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S gamesvr && \
    adduser -u 1001 -S gamesvr -G gamesvr

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé˜¶æ®µå¤åˆ¶å¯æ‰§è¡Œæ–‡ä»¶
COPY --from=builder --chown=gamesvr:gamesvr /app/activity-service .
COPY --from=builder --chown=gamesvr:gamesvr /app/configs ./configs
COPY --from=builder --chown=gamesvr:gamesvr /app/scripts/entrypoint.sh .

# è®¾ç½®æƒé™
RUN chmod +x activity-service entrypoint.sh

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER gamesvr

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 8080 50051

# å¯åŠ¨å‘½ä»¤
ENTRYPOINT ["./entrypoint.sh"]
```

### 2. ä¸åŒç±»å‹æœåŠ¡çš„Dockerfileå·®å¼‚

```dockerfile
# ç½‘å…³æœåŠ¡ï¼ˆéœ€è¦ä¼˜åŒ–ç½‘ç»œæ€§èƒ½ï¼‰
FROM golang:1.21-alpine AS builder
# ç½‘å…³éœ€è¦CGOæ”¯æŒepollç­‰ç³»ç»Ÿè°ƒç”¨
RUN apk add --no-cache gcc musl-dev linux-headers
ENV CGO_ENABLED=1
...
```

### 3. åŸºç¡€é•œåƒä¼˜åŒ–

```dockerfile
# ä½¿ç”¨distrolessé•œåƒï¼ˆæ›´å®‰å…¨ã€æ›´å°ï¼‰
FROM gcr.io/distroless/static-debian11

# æˆ–è€…ä½¿ç”¨scratché•œåƒï¼ˆæœ€å°åŒ–ï¼‰
FROM scratch
COPY --from=builder /app/activity-service /
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
```

## ä¸‰ã€Docker Composeæœ¬åœ°å¼€å‘ç¯å¢ƒ

### 1. å®Œæ•´çš„æ¸¸æˆå¼€å‘ç¯å¢ƒç¼–æ’

```yaml
# docker-compose.yml
version: '3.8'

services:
  # åŸºç¡€è®¾æ–½æœåŠ¡
  zookeeper:
    image: zookeeper:3.8
    container_name: game-zookeeper
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOO_MY_ID: 1
    volumes:
      - zookeeper_data:/data
      - zookeeper_datalog:/datalog
    networks:
      - game-network

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: game-kafka
    restart: unless-stopped
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - game-network

  redis-cluster:
    image: bitnami/redis-cluster:7.0
    container_name: game-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
      - "16379:16379"
    environment:
      - REDIS_PASSWORD=game_redis_pass
      - REDIS_NODES=redis-cluster
      - REDIS_CLUSTER_REPLICAS=1
    volumes:
      - redis_data:/bitnami/redis/data
    networks:
      - game-network
    command: >
      /opt/bitnami/scripts/redis-cluster/entrypoint.sh
      /opt/bitnami/scripts/redis-cluster/run.sh

  mysql:
    image: mysql:8.0
    container_name: game-mysql
    restart: unless-stopped
    command: 
      --default-authentication-plugin=mysql_native_password
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_unicode_ci
    environment:
      MYSQL_ROOT_PASSWORD: game_root_pass
      MYSQL_DATABASE: game_platform
      MYSQL_USER: game_user
      MYSQL_PASSWORD: game_user_pass
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init-scripts:/docker-entrypoint-initdb.d
    networks:
      - game-network
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5

  nacos:
    image: nacos/nacos-server:v2.2.3
    container_name: game-nacos
    restart: unless-stopped
    environment:
      - MODE=standalone
      - SPRING_DATASOURCE_PLATFORM=mysql
      - MYSQL_SERVICE_HOST=mysql
      - MYSQL_SERVICE_DB_NAME=nacos_config
      - MYSQL_SERVICE_PORT=3306
      - MYSQL_SERVICE_USER=game_user
      - MYSQL_SERVICE_PASSWORD=game_user_pass
      - NACOS_AUTH_ENABLE=true
      - NACOS_AUTH_USERNAME=nacos
      - NACOS_AUTH_PASSWORD=nacos
    ports:
      - "8848:8848"
      - "9848:9848"
    depends_on:
      mysql:
        condition: service_healthy
    volumes:
      - nacos_data:/home/nacos/data
    networks:
      - game-network

  # æ¸¸æˆä¸šåŠ¡æœåŠ¡
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile.dev
    container_name: game-gateway
    restart: unless-stopped
    ports:
      - "8000:8000"    # WebSocketç«¯å£
      - "8001:8001"    # HTTPç«¯å£
      - "9000:9000"    # ç®¡ç†ç«¯å£
    environment:
      - APP_PROFILE=dev
      - NACOS_HOST=nacos
      - NACOS_PORT=8848
      - REDIS_HOST=redis-cluster
      - REDIS_PORT=6379
    volumes:
      - ./gateway:/app
      - /app/node_modules
    depends_on:
      - nacos
      - redis-cluster
    networks:
      - game-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  activity-service:
    build:
      context: ./activity-service
      dockerfile: Dockerfile.dev
    container_name: game-activity
    restart: unless-stopped
    ports:
      - "50051:50051"
      - "8081:8080"
    environment:
      - APP_PROFILE=dev
      - NACOS_HOST=nacos
      - NACOS_PORT=8848
      - DB_HOST=mysql
      - DB_PORT=3306
      - REDIS_HOST=redis-cluster
      - KAFKA_HOST=kafka
    volumes:
      - ./activity-service:/app
    depends_on:
      - nacos
      - mysql
      - redis-cluster
      - kafka
    networks:
      - game-network

  matching-service:
    build:
      context: ./matching-service
      dockerfile: Dockerfile.dev
    container_name: game-matching
    restart: unless-stopped
    environment:
      - APP_PROFILE=dev
      - NACOS_HOST=nacos
    depends_on:
      - nacos
    networks:
      - game-network

  # ç›‘æ§ä¸æ—¥å¿—
  prometheus:
    image: prom/prometheus:latest
    container_name: game-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - game-network

  grafana:
    image: grafana/grafana:latest
    container_name: game-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - game-network

  loki:
    image: grafana/loki:2.8.0
    container_name: game-loki
    restart: unless-stopped
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - loki_data:/loki
      - ./monitoring/loki-config.yaml:/etc/loki/local-config.yaml
    networks:
      - game-network

  promtail:
    image: grafana/promtail:2.8.0
    container_name: game-promtail
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./monitoring/promtail-config.yaml:/etc/promtail/config.yaml
      - ./activity-service/logs:/var/log/activity-service
      - ./gateway/logs:/var/log/gateway
    command:
      - -config.file=/etc/promtail/config.yaml
    depends_on:
      - loki
    networks:
      - game-network

networks:
  game-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1

volumes:
  zookeeper_data:
  zookeeper_datalog:
  kafka_data:
  redis_data:
  mysql_data:
  nacos_data:
  prometheus_data:
  grafana_data:
  loki_data:
```

### 2. å¼€å‘ç¯å¢ƒå¯åŠ¨è„šæœ¬

```bash
#!/bin/bash
# start-dev.sh

set -e

echo "ğŸš€ å¯åŠ¨æ¸¸æˆå¼€å‘ç¯å¢ƒ..."

# 1. æ£€æŸ¥ç¯å¢ƒ
if ! command -v docker &> /dev/null; then
    echo "âŒ è¯·å…ˆå®‰è£…Docker"
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    echo "âŒ è¯·å…ˆå®‰è£…Docker Compose"
    exit 1
fi

# 2. åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs/{gateway,activity,matching}
mkdir -p data/{mysql,redis,kafka}

# 3. è®¾ç½®ç¯å¢ƒå˜é‡
export COMPOSE_PROJECT_NAME=game_dev
export COMPOSE_DOCKER_CLI_BUILD=1
export DOCKER_BUILDKIT=1

# 4. æ„å»ºå¹¶å¯åŠ¨æœåŠ¡
echo "ğŸ“¦ æ„å»ºDockeré•œåƒ..."
docker-compose build --parallel --compress

echo "ğŸš¢ å¯åŠ¨æœåŠ¡..."
docker-compose up -d

# 5. ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å°±ç»ª..."
sleep 10

# 6. æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# 7. è¾“å‡ºè®¿é—®ä¿¡æ¯
echo ""
echo "âœ… å¼€å‘ç¯å¢ƒå¯åŠ¨å®Œæˆï¼"
echo "========================"
echo "ğŸŒ è®¿é—®åœ°å€ï¼š"
echo "ç½‘å…³æœåŠ¡ï¼š      ws://localhost:8000"
echo "Nacosé…ç½®ä¸­å¿ƒï¼š http://localhost:8848/nacos (è´¦å·: nacos/nacos)"
echo "Grafanaç›‘æ§ï¼š   http://localhost:3000 (è´¦å·: admin/admin)"
echo "Prometheusï¼š    http://localhost:9090"
echo ""
echo "ğŸ“ å¸¸ç”¨å‘½ä»¤ï¼š"
echo "æŸ¥çœ‹æ—¥å¿—ï¼š      docker-compose logs -f [æœåŠ¡å]"
echo "é‡å¯æœåŠ¡ï¼š      docker-compose restart [æœåŠ¡å]"
echo "åœæ­¢ç¯å¢ƒï¼š      docker-compose down"
echo "é‡å»ºæœåŠ¡ï¼š      docker-compose up -d --build [æœåŠ¡å]"
```

## å››ã€ç”Ÿäº§ç¯å¢ƒKuberneteséƒ¨ç½²

### 1. Kuberneteséƒ¨ç½²æ–‡ä»¶ç»“æ„

```
k8s/
â”œâ”€â”€ base/                    # åŸºç¡€é…ç½®
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ configmap-base.yaml
â”‚   â””â”€â”€ secrets-base.yaml
â”œâ”€â”€ overlays/               # ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”œâ”€â”€ configmap-env.yaml
â”‚   â”‚   â””â”€â”€ deployment-patch.yaml
â”‚   â”œâ”€â”€ staging/
â”‚   â””â”€â”€ prod/
â”œâ”€â”€ services/              # æœåŠ¡å®šä¹‰
â”‚   â”œâ”€â”€ activity/
â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”œâ”€â”€ hpa.yaml
â”‚   â”‚   â””â”€â”€ pdb.yaml
â”‚   â”œâ”€â”€ gateway/
â”‚   â””â”€â”€ matching/
â”œâ”€â”€ infrastructure/        # åŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ redis-cluster/
â”‚   â”œâ”€â”€ mysql/
â”‚   â””â”€â”€ kafka/
â””â”€â”€ monitoring/           # ç›‘æ§
    â”œâ”€â”€ prometheus/
    â””â”€â”€ grafana/
```

### 2. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²é…ç½®

```yaml
# k8s/services/activity/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: activity-service
  namespace: game-prod
  labels:
    app: activity-service
    component: game-backend
    tier: business
spec:
  replicas: 3
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: activity-service
  template:
    metadata:
      labels:
        app: activity-service
        version: v1.2.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      # äº²å’Œæ€§é…ç½® - æ‰“æ•£éƒ¨ç½²
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - activity-service
              topologyKey: kubernetes.io/hostname
      
      # èŠ‚ç‚¹é€‰æ‹©å™¨ - é€‰æ‹©é«˜æ€§èƒ½èŠ‚ç‚¹
      nodeSelector:
        node-type: game-server
      
      # ä¼˜å…ˆçº§
      priorityClassName: high-priority
      
      containers:
      - name: activity-service
        image: registry.game.com/activity-service:v1.2.0
        imagePullPolicy: Always
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: grpc
          containerPort: 50051
          protocol: TCP
        
        # èµ„æºé™åˆ¶
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        
        # ç¯å¢ƒå˜é‡
        env:
        - name: APP_PROFILE
          value: "prod"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        
        # é…ç½®é€šè¿‡ConfigMapæŒ‚è½½
        envFrom:
        - configMapRef:
            name: game-activity-config
        - secretRef:
            name: game-db-secret
        
        # é…ç½®æ–‡ä»¶æŒ‚è½½
        volumeMounts:
        - name: config-volume
          mountPath: /app/configs
          readOnly: true
        - name: logs-volume
          mountPath: /app/logs
        
        # å¥åº·æ£€æŸ¥
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          successThreshold: 1
          failureThreshold: 3
        
        # ç”Ÿå‘½å‘¨æœŸé’©å­
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 30"]
        
        # å®‰å…¨ä¸Šä¸‹æ–‡
        securityContext:
          runAsUser: 1001
          runAsGroup: 1001
          readOnlyRootFilesystem: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
        
        # æ—¥å¿—æ”¶é›†
        args:
        - "--log.format=json"
        - "--log.level=info"
      
      # åˆå§‹åŒ–å®¹å™¨
      initContainers:
      - name: init-config
        image: busybox:1.28
        command: ['sh', '-c', 'cp /app/config-templates/* /app/configs/']
        volumeMounts:
        - name: config-template-volume
          mountPath: /app/config-templates
        - name: config-volume
          mountPath: /app/configs
      
      # å·å®šä¹‰
      volumes:
      - name: config-template-volume
        configMap:
          name: activity-config-template
      - name: config-volume
        emptyDir: {}
      - name: logs-volume
        emptyDir: {}
      
      # æœåŠ¡è´¦æˆ·
      serviceAccountName: game-service-account
      
      # DNSé…ç½®
      dnsConfig:
        options:
        - name: ndots
          value: "2"
        - name: single-request-reopen
```

```yaml
# k8s/services/activity/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: activity-service
  namespace: game-prod
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-internal: "true"
    prometheus.io/scrape: "true"
spec:
  selector:
    app: activity-service
  ports:
  - name: http
    port: 8080
    targetPort: 8080
    protocol: TCP
  - name: grpc
    port: 50051
    targetPort: 50051
    protocol: TCP
  - name: metrics
    port: 9100
    targetPort: 9100
    protocol: TCP
  type: ClusterIP
  sessionAffinity: None
```

```yaml
# k8s/services/activity/hpa.yaml - æ°´å¹³è‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: activity-service-hpa
  namespace: game-prod
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: activity-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: active_connections
      target:
        type: AverageValue
        averageValue: 5000
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 60
```

### 3. æ¸¸æˆä¸“ç”¨ä¼˜åŒ–é…ç½®

```yaml
# k8s/optimizations/game-optimization.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: game-kernel-params
  namespace: kube-system
data:
  99-game-optimizations.conf: |
    # ç½‘ç»œä¼˜åŒ–
    net.core.rmem_max = 134217728
    net.core.wmem_max = 134217728
    net.ipv4.tcp_rmem = 4096 87380 134217728
    net.ipv4.tcp_wmem = 4096 65536 134217728
    net.ipv4.tcp_congestion_control = bbr
    net.ipv4.tcp_tw_reuse = 1
    net.ipv4.tcp_fin_timeout = 30
    
    # æ–‡ä»¶æè¿°ç¬¦
    fs.file-max = 1000000
    fs.nr_open = 1000000
    
    # è¿æ¥è·Ÿè¸ª
    net.netfilter.nf_conntrack_max = 1048576
    net.nf_conntrack_max = 1048576
---
apiVersion: v1
kind: DaemonSet
metadata:
  name: game-optimizer
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: game-optimizer
  template:
    metadata:
      labels:
        name: game-optimizer
    spec:
      hostNetwork: true
      containers:
      - name: optimizer
        image: busybox:1.28
        command: ["/bin/sh", "-c"]
        args:
          - |
            # åº”ç”¨å†…æ ¸å‚æ•°
            sysctl -p /etc/sysctl.d/99-game-optimizations.conf
            # æŒç»­è¿è¡Œ
            tail -f /dev/null
        volumeMounts:
        - name: sysctl-conf
          mountPath: /etc/sysctl.d
        securityContext:
          privileged: true
      volumes:
      - name: sysctl-conf
        configMap:
          name: game-kernel-params
      tolerations:
      - operator: Exists
```

## äº”ã€CI/CDæµæ°´çº¿é…ç½®

### 1. GitLab CI/CDç¤ºä¾‹

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - scan
  - deploy-dev
  - deploy-staging
  - deploy-prod

variables:
  DOCKER_HOST: tcp://docker:2375
  DOCKER_TLS_CERTDIR: ""
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA

# æœåŠ¡ç‰¹å®šé…ç½®
.activity-service: &activity-service
  variables:
    SERVICE_NAME: activity-service
    DOCKERFILE_PATH: Dockerfile
  before_script:
    - echo "Building $SERVICE_NAME"
  after_script:
    - echo "Cleanup..."

# 1. å•å…ƒæµ‹è¯•
unit-test:
  stage: test
  script:
    - go test ./... -v -coverprofile=coverage.out
    - go tool cover -func=coverage.out
  artifacts:
    paths:
      - coverage.out
    reports:
      cobertura: coverage.xml
  only:
    - merge_requests
    - main
    - develop

# 2. ä»£ç æ‰«æ
code-quality:
  stage: scan
  image: sonarsource/sonar-scanner-cli:latest
  variables:
    SONAR_USER_HOME: "${CI_PROJECT_DIR}/.sonar"
    GIT_DEPTH: "0"
  cache:
    key: "${CI_JOB_NAME}"
    paths:
      - .sonar/cache
  script:
    - sonar-scanner
  allow_failure: true

# 3. æ„å»ºDockeré•œåƒ
build-activity-service:
  <<: *activity-service
  stage: build
  image: docker:20.10.16
  services:
    - docker:20.10.16-dind
  script:
    # ç™»å½•é•œåƒä»“åº“
    - echo "$CI_REGISTRY_PASSWORD" | docker login $CI_REGISTRY -u $CI_REGISTRY_USER --password-stdin
    
    # æ„å»ºé•œåƒ
    - docker build \
        --build-arg VERSION=$CI_COMMIT_SHORT_SHA \
        --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
        -t $IMAGE_TAG \
        -f $DOCKERFILE_PATH .
    
    # å®‰å…¨æ‰«æ
    - docker scan --accept-license --exclude-base $IMAGE_TAG || true
    
    # æ¨é€é•œåƒ
    - docker push $IMAGE_TAG
    
    # æ ‡è®°ä¸ºlatestï¼ˆä»…mainåˆ†æ”¯ï¼‰
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        docker tag $IMAGE_TAG $CI_REGISTRY_IMAGE:latest
        docker push $CI_REGISTRY_IMAGE:latest
      fi
  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json

# 4. éƒ¨ç½²åˆ°å¼€å‘ç¯å¢ƒ
deploy-dev:
  stage: deploy-dev
  image: bitnami/kubectl:latest
  environment:
    name: development
    url: https://dev.game.com
  script:
    - |
      kubectl config use-context dev-cluster
      kubectl set image deployment/activity-service \
        activity-service=$IMAGE_TAG \
        -n game-dev
      kubectl rollout status deployment/activity-service -n game-dev
  only:
    - develop

# 5. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
deploy-prod:
  stage: deploy-prod
  image: bitnami/kubectl:latest
  environment:
    name: production
    url: https://game.com
  script:
    - |
      # ä½¿ç”¨Kustomizeéƒ¨ç½²
      kubectl config use-context prod-cluster
      cd k8s/overlays/prod
      kustomize edit set image activity-service=$IMAGE_TAG
      kubectl apply -k .
      
      # è“ç»¿éƒ¨ç½²éªŒè¯
      kubectl rollout status deployment/activity-service -n game-prod --timeout=300s
      
      # å¥åº·æ£€æŸ¥
      ./scripts/health-check.sh
  only:
    - main
  when: manual
  dependencies:
    - build-activity-service
```

### 2. éƒ¨ç½²éªŒè¯è„šæœ¬

```bash
#!/bin/bash
# scripts/health-check.sh

set -e

SERVICE_NAME="activity-service"
NAMESPACE="game-prod"
TIMEOUT=300
INTERVAL=10

echo "ğŸ” å¼€å§‹å¥åº·æ£€æŸ¥ $SERVICE_NAME..."

# 1. æ£€æŸ¥PodçŠ¶æ€
echo "æ£€æŸ¥PodçŠ¶æ€..."
end=$((SECONDS+TIMEOUT))
while [ $SECONDS -lt $end ]; do
    READY=$(kubectl get deployment $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.readyReplicas}')
    DESIRED=$(kubectl get deployment $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.status.replicas}')
    
    if [ "$READY" == "$DESIRED" ] && [ "$READY" != "0" ]; then
        echo "âœ… Podå…¨éƒ¨å°±ç»ª ($READY/$DESIRED)"
        break
    fi
    
    echo "ç­‰å¾…Podå°±ç»ª ($READY/$DESIRED)..."
    sleep $INTERVAL
done

if [ "$READY" != "$DESIRED" ]; then
    echo "âŒ Podæœªåœ¨è§„å®šæ—¶é—´å†…å°±ç»ª"
    exit 1
fi

# 2. è·å–æœåŠ¡ç«¯ç‚¹
ENDPOINT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.clusterIP}')
HTTP_PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[?(@.name=="http")].port}')

# 3. æ£€æŸ¥HTTPå¥åº·ç«¯ç‚¹
echo "æ£€æŸ¥HTTPå¥åº·ç«¯ç‚¹..."
if curl -f http://$ENDPOINT:$HTTP_PORT/health; then
    echo "âœ… å¥åº·æ£€æŸ¥é€šè¿‡"
else
    echo "âŒ å¥åº·æ£€æŸ¥å¤±è´¥"
    exit 1
fi

# 4. æ£€æŸ¥gRPCå¥åº·çŠ¶æ€
echo "æ£€æŸ¥gRPCå¥åº·çŠ¶æ€..."
GRPC_PORT=$(kubectl get svc $SERVICE_NAME -n $NAMESPACE -o jsonpath='{.spec.ports[?(@.name=="grpc")].port}')

# ä½¿ç”¨grpc_health_probe
if ./bin/grpc_health_probe -addr=$ENDPOINT:$GRPC_PORT; then
    echo "âœ… gRPCå¥åº·æ£€æŸ¥é€šè¿‡"
else
    echo "âŒ gRPCå¥åº·æ£€æŸ¥å¤±è´¥"
    exit 1
fi

# 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
echo "è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."
ab -n 1000 -c 100 http://$ENDPOINT:$HTTP_PORT/metrics > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡"
else
    echo "âš ï¸  æ€§èƒ½åŸºå‡†æµ‹è¯•è­¦å‘Š"
fi

echo "ğŸ‰ $SERVICE_NAME éƒ¨ç½²éªŒè¯å®Œæˆ"
```

## å…­ã€ç›‘æ§ä¸æ—¥å¿—æ”¶é›†

### 1. Dockeræ—¥å¿—é…ç½®

```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3",
    "labels": "service_name,environment",
    "tag": "{{.ImageName}}|{{.Name}}|{{.ID}}"
  }
}
```

### 2. ç»“æ„åŒ–æ—¥å¿—è¾“å‡º

```go
// åœ¨GoæœåŠ¡ä¸­ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
import "github.com/sirupsen/logrus"

func initLogger() *logrus.Logger {
    logger := logrus.New()
    
    if env.IsProduction() {
        logger.SetFormatter(&logrus.JSONFormatter{
            TimestampFormat: "2006-01-02T15:04:05.999Z07:00",
            FieldMap: logrus.FieldMap{
                logrus.FieldKeyTime:  "@timestamp",
                logrus.FieldKeyLevel: "level",
                logrus.FieldKeyMsg:   "message",
                logrus.FieldKeyFunc:  "function",
            },
        })
    }
    
    return logger
}

// ä½¿ç”¨ç¤ºä¾‹
logger.WithFields(logrus.Fields{
    "service":    "activity-service",
    "user_id":     userID,
    "activity_id": activityID,
    "duration_ms": duration.Milliseconds(),
    "trace_id":    traceID,
}).Info("User joined activity")
```

## ä¸ƒã€æœ€ä½³å®è·µæ€»ç»“

### 1. é•œåƒä¼˜åŒ–
- ä½¿ç”¨å¤šé˜¶æ®µæ„å»ºå‡å°é•œåƒå¤§å°
- ä½¿ç”¨Alpineæˆ–distrolessåŸºç¡€é•œåƒ
- ç§»é™¤è°ƒè¯•å·¥å…·å’ŒåŒ…ç®¡ç†å™¨

### 2. å®‰å…¨å¼ºåŒ–
- ä½¿ç”¨érootç”¨æˆ·è¿è¡Œå®¹å™¨
- è®¾ç½®åªè¯»æ ¹æ–‡ä»¶ç³»ç»Ÿ
- ç§»é™¤ä¸å¿…è¦çš„Linux capabilities
- æ‰«æé•œåƒä¸­çš„å®‰å…¨æ¼æ´

### 3. æ€§èƒ½ä¼˜åŒ–
- è®¾ç½®åˆç†çš„CPUå’Œå†…å­˜é™åˆ¶
- ä½¿ç”¨æœ¬åœ°SSDå­˜å‚¨å…³é”®æ•°æ®
- ä¼˜åŒ–ç½‘ç»œé…ç½®ï¼ˆTCPå‚æ•°è°ƒæ•´ï¼‰
- åˆç†è®¾ç½®å¥åº·æ£€æŸ¥é—´éš”

### 4. å¯è§‚æµ‹æ€§
- æ‰€æœ‰æœåŠ¡æš´éœ²/metricsç«¯ç‚¹
- ç»“æ„åŒ–æ—¥å¿—è¾“å‡ºJSONæ ¼å¼
- åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ
- ä¸šåŠ¡æŒ‡æ ‡åŸ‹ç‚¹

### 5. æ¸¸æˆæœåŠ¡ç‰¹æ®Šè€ƒè™‘
- é•¿è¿æ¥æœåŠ¡çš„ä¼˜é›…ç»ˆæ­¢
- çŠ¶æ€æœåŠ¡çš„æŒä¹…åŒ–å­˜å‚¨
- æˆ˜æ–—æœåŠ¡çš„ä½å»¶è¿Ÿè¦æ±‚
- ç½‘å…³æœåŠ¡çš„è¿æ¥ç®¡ç†

é€šè¿‡ä»¥ä¸ŠDockeråŒ–å’Œéƒ¨ç½²å®è·µï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªç¨³å®šã€å¯æ‰©å±•ã€æ˜“ç»´æŠ¤çš„æ¸¸æˆå¾®æœåŠ¡æ¶æ„ã€‚
